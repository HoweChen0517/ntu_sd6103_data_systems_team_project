{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: /Users/howechen/Project/ntu_sd6103_team_project/ntu_sd6103_data_systems_team_project\n"
     ]
    }
   ],
   "source": [
    "if os.getcwd().endswith('notebook'):\n",
    "    os.chdir('../')\n",
    "print(f'current working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record 1: {'type': 'proceedings', 'id': 'reference/med/2013', 'date': '2017-05-16', 'editor': 'Ankur Agarwal', 'title': 'Handbook of Medical and Healthcare Technologies', 'year': '2013', 'publisher': 'Springer', 'ee': 'https://doi.org/10.1007/978-1-4614-8495-0', 'isbn': '978-1-4614-8494-3', 'url': 'db/reference/med/med2013.html'}\n",
      "Record 2: {'type': 'proceedings', 'id': 'reference/genetic/2015', 'date': '2020-03-27', 'editor': 'Conor Ryan', 'title': 'Handbook of Genetic Programming Applications', 'publisher': 'Springer', 'year': '2015', 'isbn': '978-3-319-20882-4', 'ee': 'https://doi.org/10.1007/978-3-319-20883-1', 'url': 'db/reference/genetic/genetic2015.html'}\n",
      "Record 3: {'type': 'proceedings', 'id': 'series/isrl/97', 'date': '2017-05-16', 'editor': 'Seda Yanik', 'title': 'Intelligent Decision Making in Quality Management - Theory and Applications', 'publisher': 'Springer', 'year': '2016', 'series': 'Intelligent Systems Reference Library', 'volume': '97', 'isbn': '978-3-319-24497-6', 'ee': 'https://doi.org/10.1007/978-3-319-24499-0', 'url': 'db/series/isrl/isrl97.html'}\n",
      "Record 4: {'type': 'proceedings', 'id': 'series/sapere/2013-5', 'date': '2019-09-06', 'editor': 'ller', 'title': 'Philosophy and Theory of Artificial Intelligence, PT-AI 2011, Thessaloniki, Greece, October 3-4, 2011, Proceedings.', 'booktitle': 'PT-AI', 'year': '2013', 'publisher': 'Springer', 'isbn': '978-3-642-31673-9', 'series': 'Studies in Applied Philosophy, Epistemology and Rational Ethics', 'volume': '5', 'ee': 'https://doi.org/10.1007/978-3-642-31674-6', 'url': 'db/series/sapere/sapere5.html'}\n",
      "Record 5: {'type': 'proceedings', 'id': 'series/ssw/49', 'date': '2021-04-19', 'editor': 'Gian Luca Pozzato', 'title': 'Applications and Practices in Ontology Design, Extraction, and Reasoning.', 'publisher': 'IOS Press', 'year': '2020', 'booktitle': 'Applications and Practices in Ontology Design, Extraction, and Reasoning', 'series': 'Studies on the Semantic Web', 'volume': '49', 'isbn': '978-1-64368-143-6', 'ee': 'https://doi.org/10.3233/SSW49', 'url': 'db/series/ssw/ssw49.html'}\n",
      "Found and printed 5 records of 'proceedings'\n"
     ]
    }
   ],
   "source": [
    "class Find_K_Records(xml.sax.ContentHandler):\n",
    "    def __init__(self, target_type, k):\n",
    "        super().__init__()\n",
    "        self.current_element = \"\"\n",
    "        self.current_data = {}\n",
    "        self.record_count = 0  # 用于计数已找到的记录\n",
    "        self.found_target = False  # 标记是否找到目标记录\n",
    "        self.target_type = target_type\n",
    "\n",
    "    def startElement(self, tag, attributes):\n",
    "        self.current_element = tag\n",
    "        # 如果找到incollection类型的记录，则初始化记录数据\n",
    "        if tag == self.target_type:\n",
    "            self.current_data = {\"type\": tag, \"id\": attributes[\"key\"], \"date\": attributes[\"mdate\"]}\n",
    "            self.found_target = True\n",
    "\n",
    "    def endElement(self, tag):\n",
    "        # 在incollection的记录结束时打印该记录的所有元素\n",
    "        if tag == self.target_type and self.found_target:\n",
    "            self.record_count += 1\n",
    "            print(f\"Record {self.record_count}: {self.current_data}\")\n",
    "            self.found_target = False  # 重置标志\n",
    "\n",
    "            # 如果只需要查看一条记录，这里可以终止解析\n",
    "            if self.record_count == k:\n",
    "                raise xml.sax.SAXException(\"Found target, stop parsing\")  # 通过抛出异常停止解析\n",
    "\n",
    "        # 在找到incollection的记录时，将当前元素的内容添加到记录中\n",
    "        if self.found_target and self.current_element:\n",
    "            self.current_data[self.current_element] = self.content\n",
    "\n",
    "    def characters(self, content):\n",
    "        # 记录当前元素的内容\n",
    "        self.content = content.strip()\n",
    "\n",
    "# 初始化解析器和处理器\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "target_type = \"proceedings\"\n",
    "k = 5\n",
    "handler = Find_K_Records(target_type=target_type, k=k)\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "# 解析XML文件\n",
    "xml_file = \"../ntu_sd6103_team_project_data/dblp.xml\"\n",
    "try:\n",
    "    parser.parse(xml_file)\n",
    "except xml.sax.SAXException:\n",
    "    print(f\"Found and printed {k} records of '{target_type}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incollection record:**\n",
    "- type: incollection (no null)\n",
    "- id: one and only (no null)\n",
    "- date: date (no null)\n",
    "- author\n",
    "- title: incollection title\n",
    "- year: year\n",
    "- booktitle:\n",
    "- ee\n",
    "- url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class incollectionParser(xml.sax.ContentHandler):\n",
    "    def __init__(self, batch_size=5000):\n",
    "        super().__init__()\n",
    "        self.current_element = \"\"\n",
    "        self.current_data = {}\n",
    "        self.records = []\n",
    "        self.authors = []\n",
    "        self.orcid = []\n",
    "        self.batch_size = batch_size\n",
    "        self.file_count = 1\n",
    "\n",
    "    def startElement(self, tag, attributes):\n",
    "        self.current_element = tag\n",
    "        if tag == 'incollection':\n",
    "            # Reset for each new publication record\n",
    "            # print(self.current_data)\n",
    "            # print(f\"*****Processing {tag}...******\")\n",
    "            self.current_data = {\n",
    "                \"type\": tag,\n",
    "                \"id\": attributes[\"key\"],\n",
    "                \"date\": attributes[\"mdate\"],\n",
    "                \"title\": \"\",\n",
    "                \"pages\": \"\",\n",
    "                \"year\": \"\",\n",
    "                \"booktitle\": \"\",\n",
    "                \"publisher\": \"\",\n",
    "                \"ee\": \"\",\n",
    "                \"url\": \"\"\n",
    "            }\n",
    "            self.authors = []\n",
    "\n",
    "    def endElement(self, tag):\n",
    "        if tag in [\"incollection\"]:\n",
    "            # Add authors as a comma-separated string\n",
    "            self.current_data[\"authors\"] = \", \".join(self.authors)\n",
    "            self.records.append(self.current_data)\n",
    "            if len(self.records) >= self.batch_size:\n",
    "                self.save_to_csv()\n",
    "                self.records = []  # Reset records\n",
    "        elif tag == \"author\":\n",
    "            # Append author to authors list\n",
    "            self.authors.append(self.content)\n",
    "            # print(f\"author: {self.content}\")\n",
    "        elif tag in self.current_data:\n",
    "            # Save the content to the current field\n",
    "            self.current_data[tag] = self.content\n",
    "            # print(f\"{tag}: {self.content}\")\n",
    "\n",
    "    def characters(self, content):\n",
    "        self.content = content.strip()\n",
    "\n",
    "    def save_to_csv(self):\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files/incollection'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files/incollection')\n",
    "        csv_file = f\"../ntu_sd6103_team_project_data/csv_files/incollection/dplr_incollection_part_{self.file_count}.csv\"\n",
    "        with open(csv_file, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.records[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.records)\n",
    "        print(f\"Saving batch {self.file_count} to {csv_file}\")\n",
    "        self.file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phdthesis record:\n",
    "\n",
    "- type: phdthesis\n",
    "- id: \n",
    "- date\n",
    "- author\n",
    "- title\n",
    "- publisher\n",
    "- year\n",
    "- series\n",
    "- volume\n",
    "- pages\n",
    "- school\n",
    "- isbn\n",
    "- ee\n",
    "- note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class phdthesisParser(xml.sax.ContentHandler):\n",
    "    def __init__(self, batch_size=5000):\n",
    "        super().__init__()\n",
    "        self.current_element = \"\"\n",
    "        self.current_data = {}\n",
    "        self.records = []\n",
    "        self.authors = []\n",
    "        self.batch_size = batch_size\n",
    "        self.file_count = 1\n",
    "\n",
    "    def startElement(self, tag, attributes):\n",
    "        self.current_element = tag\n",
    "        if tag == 'phdthesis':\n",
    "            # Reset for each new publication record\n",
    "            # print(self.current_data)\n",
    "            # print(f\"*****Processing {tag}...******\")\n",
    "            self.current_data = {\n",
    "                \"type\": tag,\n",
    "                \"id\": attributes[\"key\"],\n",
    "                \"date\": attributes[\"mdate\"],\n",
    "                \"title\": \"\",\n",
    "                \"pages\": \"\",\n",
    "                \"publisher\": \"\",\n",
    "                \"year\": \"\",\n",
    "                \"series\": \"\",\n",
    "                \"volume\": \"\",\n",
    "                \"school\": \"\",\n",
    "                \"isbn\": \"\",\n",
    "                \"ee\": \"\"\n",
    "            }\n",
    "            self.authors = []\n",
    "\n",
    "    def endElement(self, tag):\n",
    "        if tag in [\"phdthesis\"]:\n",
    "            # Add authors as a comma-separated string\n",
    "            self.current_data[\"authors\"] = \", \".join(self.authors)\n",
    "            self.records.append(self.current_data)\n",
    "            if len(self.records) >= self.batch_size:\n",
    "                self.save_to_csv()\n",
    "                self.records = []  # Reset records\n",
    "        elif tag == \"author\":\n",
    "            # Append author to authors list\n",
    "            self.authors.append(self.content)\n",
    "            # print(f\"author: {self.content}\")\n",
    "        elif tag in self.current_data:\n",
    "            # Save the content to the current field\n",
    "            self.current_data[tag] = self.content\n",
    "            # print(f\"{tag}: {self.content}\")\n",
    "\n",
    "    def characters(self, content):\n",
    "        self.content = content.strip()\n",
    "\n",
    "    def save_to_csv(self):\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files/phdthesis'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files/phdthesis')\n",
    "        csv_file = f\"../ntu_sd6103_team_project_data/csv_files/phdthesis/dplr_phdthesis_part_{self.file_count}.csv\"\n",
    "        with open(csv_file, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.records[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.records)\n",
    "        print(f\"Saving batch {self.file_count} to {csv_file}\")\n",
    "        self.file_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class masterthesisParser(xml.sax.ContentHandler):\n",
    "    def __init__(self, batch_size=5000):\n",
    "        super().__init__()\n",
    "        self.current_element = \"\"\n",
    "        self.current_data = {}\n",
    "        self.records = []\n",
    "        self.authors = []\n",
    "        self.batch_size = batch_size\n",
    "        self.file_count = 1\n",
    "\n",
    "    def startElement(self, tag, attributes):\n",
    "        self.current_element = tag\n",
    "        if tag == 'masterthesis':\n",
    "            # Reset for each new publication record\n",
    "            # print(self.current_data)\n",
    "            print(f\"*****Processing {tag}...******\")\n",
    "            self.current_data = {\n",
    "                \"type\": tag,\n",
    "                \"id\": attributes[\"key\"],\n",
    "                \"date\": attributes[\"mdate\"],\n",
    "                \"title\": \"\",\n",
    "                \"year\": \"\",\n",
    "                \"school\": \"\",\n",
    "                \"ee\": \"\"\n",
    "            }\n",
    "            self.authors = []\n",
    "\n",
    "    def endElement(self, tag):\n",
    "        if tag in [\"masterthesis\"]:\n",
    "            # Add authors as a comma-separated string\n",
    "            self.current_data[\"authors\"] = \", \".join(self.authors)\n",
    "            self.records.append(self.current_data)\n",
    "            if len(self.records) >= self.batch_size:\n",
    "                self.save_to_csv()\n",
    "                self.records = []  # Reset records\n",
    "        elif tag == \"author\":\n",
    "            # Append author to authors list\n",
    "            self.authors.append(self.content)\n",
    "            # print(f\"author: {self.content}\")\n",
    "        elif tag in self.current_data:\n",
    "            # Save the content to the current field\n",
    "            self.current_data[tag] = self.content\n",
    "            # print(f\"{tag}: {self.content}\")\n",
    "\n",
    "    def characters(self, content):\n",
    "        self.content = content.strip()\n",
    "\n",
    "    def save_to_csv(self):\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files/masterthesis'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files/masterthesis')\n",
    "        csv_file = f\"../ntu_sd6103_team_project_data/csv_files/masterthesis/dplr_masterthesis_part_{self.file_count}.csv\"\n",
    "        with open(csv_file, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.records[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.records)\n",
    "        print(f\"Saving batch {self.file_count} to {csv_file}\")\n",
    "        self.file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "www records:\n",
    "\n",
    "- type\n",
    "- id\n",
    "- date\n",
    "- title\n",
    "- pages\n",
    "- note\n",
    "- url\n",
    "- authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wwwParser(xml.sax.ContentHandler):\n",
    "    def __init__(self, batch_size=5000):\n",
    "        super().__init__()\n",
    "        self.current_element = \"\"\n",
    "        self.current_data = {}\n",
    "        self.records = []\n",
    "        self.authors = []\n",
    "        self.batch_size = batch_size  # batch size\n",
    "        self.file_count = 1  # csv No.\n",
    "\n",
    "    def startElement(self, tag, attributes):\n",
    "        self.current_element = tag\n",
    "        if tag == 'www':\n",
    "            # Reset for each new publication record\n",
    "            # print(self.current_data)\n",
    "            # print(f\"*****Processing {tag}...******\")\n",
    "            self.current_data = {\n",
    "                \"type\": tag,\n",
    "                \"id\": attributes[\"key\"],\n",
    "                \"date\": attributes[\"mdate\"],\n",
    "                \"title\": \"\",\n",
    "                \"pages\": \"\",\n",
    "                \"note\": \"\",\n",
    "                \"url\": \"\"\n",
    "            }\n",
    "            self.authors = []\n",
    "\n",
    "    def endElement(self, tag):\n",
    "        if tag in [\"www\"]:\n",
    "            # Add authors as a comma-separated string\n",
    "            self.current_data[\"authors\"] = \", \".join(self.authors)\n",
    "            self.records.append(self.current_data)\n",
    "            if len(self.records) >= self.batch_size:\n",
    "                self.save_to_csv()\n",
    "                self.records = []  # Reset records\n",
    "        elif tag == \"author\":\n",
    "            # Append author to authors list\n",
    "            self.authors.append(self.content)\n",
    "            # print(f\"author: {self.content}\")\n",
    "        elif tag in self.current_data:\n",
    "            # Save the content to the current field\n",
    "            self.current_data[tag] = self.content\n",
    "            # print(f\"{tag}: {self.content}\")\n",
    "\n",
    "    def characters(self, content):\n",
    "        self.content = content.strip()\n",
    "    \n",
    "    def save_to_csv(self):\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files/www'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files/www')\n",
    "        csv_file = f\"../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_{self.file_count}.csv\"\n",
    "        with open(csv_file, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.records[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.records)\n",
    "        print(f\"Saving batch {self.file_count} to {csv_file}\")\n",
    "        self.file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data record:\n",
    "\n",
    "- type,\n",
    "- id,\n",
    "- date,\n",
    "- title,\n",
    "- pages,\n",
    "- publisher,\n",
    "- year,\n",
    "- month,\n",
    "- ee,\n",
    "- stream,\n",
    "- rel,\n",
    "- authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataParser(xml.sax.ContentHandler):\n",
    "    def __init__(self, batch_size=5000):\n",
    "        super().__init__()\n",
    "        self.current_element = \"\"\n",
    "        self.current_data = {}\n",
    "        self.records = []\n",
    "        self.authors = []\n",
    "        self.batch_size = batch_size  # batch size\n",
    "        self.file_count = 1  # csv No.\n",
    "\n",
    "    def startElement(self, tag, attributes):\n",
    "        self.current_element = tag\n",
    "        if tag == 'data':\n",
    "            # Reset for each new publication record\n",
    "            # print(self.current_data)\n",
    "            # print(f\"*****Processing {tag}...******\")\n",
    "            self.current_data = {\n",
    "                \"type\": tag,\n",
    "                \"id\": attributes[\"key\"],\n",
    "                \"date\": attributes[\"mdate\"],\n",
    "                \"title\": \"\",\n",
    "                \"pages\": \"\",\n",
    "                \"publisher\": \"\",\n",
    "                \"year\": \"\",\n",
    "                \"month\": \"\",\n",
    "                \"ee\": \"\",\n",
    "                \"publisher\": \"\",\n",
    "                \"stream\": \"\",\n",
    "                \"rel\": \"\"\n",
    "            }\n",
    "            self.authors = []\n",
    "\n",
    "    def endElement(self, tag):\n",
    "        if tag in [\"data\"]:\n",
    "            # Add authors as a comma-separated string\n",
    "            self.current_data[\"authors\"] = \", \".join(self.authors)\n",
    "            self.records.append(self.current_data)\n",
    "            if len(self.records) >= self.batch_size:\n",
    "                self.save_to_csv()\n",
    "                self.records = []  # Reset records\n",
    "        elif tag == \"author\":\n",
    "            # Append author to authors list\n",
    "            self.authors.append(self.content)\n",
    "            # print(f\"author: {self.content}\")\n",
    "        elif tag in self.current_data:\n",
    "            # Save the content to the current field\n",
    "            self.current_data[tag] = self.content\n",
    "            # print(f\"{tag}: {self.content}\")\n",
    "\n",
    "    def characters(self, content):\n",
    "        self.content = content.strip()\n",
    "    \n",
    "    def save_to_csv(self):\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files')\n",
    "        if not os.path.exists('../ntu_sd6103_team_project_data/csv_files/data'):\n",
    "            os.mkdir('../ntu_sd6103_team_project_data/csv_files/data')\n",
    "        csv_file = f\"../ntu_sd6103_team_project_data/csv_files/data/dplr_data_part_{self.file_count}.csv\"\n",
    "        with open(csv_file, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.records[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.records)\n",
    "        print(f\"Saving batch {self.file_count} to {csv_file}\")\n",
    "        self.file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the last batch...\n",
      "Saving batch 1 to ../ntu_sd6103_team_project_data/csv_files/incollection/dplr_incollection_part_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the parser and handler\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "handler = incollectionParser(batch_size=5000000)\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "# Parse the XML file\n",
    "xml_file = \"../ntu_sd6103_team_project_data/dblp.xml\"\n",
    "parser.parse(xml_file)\n",
    "\n",
    "if handler.records:\n",
    "    print(\"Saving the last batch...\")\n",
    "    handler.save_to_csv()   # Save the last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the last batch...\n",
      "Saving batch 1 to ../ntu_sd6103_team_project_data/csv_files/phdthesis/dplr_phdthesis_part_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the parser and handler\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "handler = phdthesisParser(batch_size=50000000)\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "# Parse the XML file\n",
    "xml_file = \"../ntu_sd6103_team_project_data/dblp.xml\"\n",
    "parser.parse(xml_file)\n",
    "\n",
    "if handler.records:\n",
    "    print(\"Saving the last batch...\")\n",
    "    handler.save_to_csv()   # Save the last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parser and handler\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "handler = masterthesisParser(batch_size=500000)\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "# Parse the XML file\n",
    "xml_file = \"../ntu_sd6103_team_project_data/dblp.xml\"\n",
    "parser.parse(xml_file)\n",
    "\n",
    "if handler.records:\n",
    "    print(\"Saving the last batch...\")\n",
    "    handler.save_to_csv()   # Save the last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 1 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_1.csv\n",
      "Saving batch 2 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_2.csv\n",
      "Saving batch 3 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_3.csv\n",
      "Saving batch 4 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_4.csv\n",
      "Saving batch 5 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_5.csv\n",
      "Saving batch 6 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_6.csv\n",
      "Saving batch 7 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_7.csv\n",
      "Saving the last batch...\n",
      "Saving batch 8 to ../ntu_sd6103_team_project_data/csv_files/www/dplr_www_part_8.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the parser and handler\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "handler = wwwParser(batch_size=500000)\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "# Parse the XML file\n",
    "xml_file = \"../ntu_sd6103_team_project_data/dblp.xml\"\n",
    "parser.parse(xml_file)\n",
    "\n",
    "if handler.records:\n",
    "    print(\"Saving the last batch...\")\n",
    "    handler.save_to_csv()   # Save the last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the last batch...\n",
      "Saving batch 1 to ../ntu_sd6103_team_project_data/csv_files/data/dplr_data_part_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the parser and handler\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "handler = dataParser(batch_size=500000)\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "# Parse the XML file\n",
    "xml_file = \"../ntu_sd6103_team_project_data/dblp.xml\"\n",
    "parser.parse(xml_file)\n",
    "\n",
    "if handler.records:\n",
    "    print(\"Saving the last batch...\")\n",
    "    handler.save_to_csv()   # Save the last batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasystem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
